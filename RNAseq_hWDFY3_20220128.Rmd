---
title: "RNA-seq analysis of BMDMs overexpressing human WDFY3"
author: "Hanrui Zhang"
date: 'Compiled: `r format(Sys.Date(), "%B %d, %Y")`'
output:
  pdf_document:
    toc: yes
    toc_depth: '5'
  github_document: default
  html_document:
    toc: yes
    toc_depth: 5
    toc_float: yes
    collapsed: yes
    number_sections: no
    theme: default
    highlight: tango
    df_print: paged
    code_folding: show
editor_options:
  chunk_output_type: console
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(
  tidy = TRUE,
  tidy.opts = list(width.cutoff = 120),
  autodep = TRUE,
    cache = TRUE,
    cache.lazy = TRUE,
    dev = c("png", "pdf", "svg"),
    error = TRUE,
    fig.retina = 2,
    fig.width = 7,
    fig.height = 6,
    highlight = TRUE,
    prompt = TRUE,
    message = FALSE,
    warning = FALSE
)

```


# Sample description
* **PROJECT ID**: 211118_HANRUI_XUN_10_MOUSE_RNA_STRDPOLYA_20M_PE100_NOVASEQ 
* **TURNAROUND**: 69 DAYS    
* **SAMPLES**: XH001-XG010 (BMDM)    
* **RELEASED**: 01/28/2022    
* **Rmd**: 07_RNAseq_hWDFY3Tg_20220128
* **Date of analysis**: 02/18/2022



# Objectives
Now you have completed the transcript-level quantification using Salmon. The next step is to use txiimport to aggregate the data to gene-level for downstream analysis, e.g. differential expression analysis by DESeq2.

# Summary


# Salmon script (in terminal)
## Activate salmon (after installation)
$ conda activate salmon
## Download mouse Gencode annotation
$ Go [Genecode](https://www.gencodegenes.org/) download mouse version M25.
cd into the file where you save your data and Genecode annotation files
## Build Salmon Index
## Salmon quantification





# Outline
1. Set up working directory.
2. Load the required packages.
3. Prepare coldata table that contains the sample information
4. Define files for tximport to read by create a named vector pointing to the quantification files
5. Create a data.frame to associate transcript ID with gene ID 
6. Import data table from Salmon output using txiimport
7. write.csv to save the quantification data to the output folder
8. Explorary analysis and DE analysis
  * 8.1 Create a _DESeqDataSet_ object
  * 8.2 Pre-filtering the data
  * 8.3 Variance stablizing transformation
  * 8.4 Exploratory analysis
    - 8.4.1 Heatmap of sample distance
    - 8.4.2 PCA
    - 8.4.3 MDS
    - 8.4.4 Clustering by the top variable genes
  * 8.5 Differential expression analysis
    - 8.5.1 DE analysis and subsetting
    - 8.5.2 Diagnostic plotting
    - 8.5.2 Plotting top DE genes
    - 8.5.3 Exporting the data
9. AnnotationDb
10. Prepare the rnk file and convert to human orthologs as well for pathway analysis
11. Obtain the normalized count matrix by DESeq() with gene symbol
12. Obtain the rlog normalized count matrix by DESeq() with gene symbol
13. Visualization of DE genes using "ReportingTools".
14. Session information


# Notes
* txi$abundance is equivalent to TPM. This gene-level abundance (TPM) can be compared across genes within the same sample or across samples within the same group. For TPM, all the samples are scaled to have sum of one million. (TPM is not for DE analysis)
* Check the count of a certain gene in dds: assay(dds)["ENSMUSG00000069515.6",] or counts(dds)["ENSMUSG00000069515.6",]
* The dds after DESeq() contains normalized counts corrected for library size (sequencing depth), and sample-specific gene length biases. This link explain all the common normalization methods: https://hbctraining.github.io/DGE_workshop/lessons/02_DGE_count_normalization.html
* In DESeq2 output: 
  - The genes with adjusted p-value of NA ("not available") have less mean normalized counts than the optimal threshold. You can make the same plot as in the vignette to see how the power increases when the threshold increases. 
  - When a subset of the p values in NA, this is DESeqâ€™s way of reporting that all counts for this gene were zero, and hence no test was applied. In addition, p values can be assigned NA if the gene was excluded from analysis because it contained an extreme count outlier. For more information, see the outlier detection section of the DESeq2 vignette.
* Many of the genes shown as "NA" in $SYMBOLS after AnnotationDbi are pseudogenes or predicted genes.
* These two posts explain whether to set up the DEseq2 cutoff of LFC.
  - https://hbctraining.github.io/DGE_workshop/lessons/05_DGE_DESeq2_analysis2.html
  - https://www.biostars.org/p/383242/
* Lyz1 <- "ENSMUSG00000069515.6"

# Analysis workflow
## 1. Set up working directory.
```{r WD, echo = FALSE}
# working directory
wd <- list()

# commonly used paths in my working directory
wd$data <- "/Users/hanruizhang/OneDrive - cumc.columbia.edu/0_Bioinformatics/Project_Wdfy3/data/07_RNAseq_hWDFY3Tg_20220128/"
wd$output <- "/Users/hanruizhang/OneDrive\ -\ cumc.columbia.edu/0_Bioinformatics/Project_Wdfy3/output/07_RNAseq_hWDFY3Tg_20220128/"
```


## 2. Load the required packages 
```{r init}
library(devtools)
library(BiocStyle)
library(knitr)
library(rmarkdown)
library(dplyr)
library(ggplot2)
library(pheatmap)
library(RColorBrewer)
library(tximport)
library(gplots)
library(cowplot)
library(shiny)
```

## 3. Prepare coldata table that contains the sample information
```{r coldata}
# Create a csv file containing the sample information, read the file and check everything looks correct
coldata <- read.csv(paste0(wd$data, "hWDFY3Tg_Samples.csv"), header = T, sep = ",")
head(coldata)
colnames(coldata)
idx <- c("id","subject","treatment")
coldata[,idx]
coldata
```

```{r coldata2, results= FALSE}
# Change numeric number to factor as needed and check
levels(coldata$id)
coldata$subject <- as.factor(coldata$subject)
coldata$treatment <- as.factor(coldata$treatment)
levels(coldata$subject)
levels(coldata$treatment)

```


## 4. Define files for tximport to read by create a named vector pointing to the quantification files
```{r quant}
list.files(file.path(wd$data))
files <- file.path(wd$data,coldata$id,"quant.sf")
names(files) <- coldata$id
all(file.exists(files)) # the output should be "TRUE"
files
```

## 5. Create a data.frame to associate transcript ID with gene ID 
This data.frame is required because transcripts IDs in salmon need to be associated with gene IDs for gene-level summarization
```{r TxDb}
# Make TxDb - saveDb to make it quicker next time
library(rtracklayer)
library(GenomicFeatures)
gtf <- paste0(wd$data, "gencode.vM28.annotation.gtf.gz")
txdb.filename <- "gencode.vM28.annotation.sqlite"
txdb <- makeTxDbFromGFF(gtf) # This step takes some time.
saveDb(txdb, txdb.filename)

# Once the TxDb database has been generated and saved, it can be quickly reloaded:
#### txdb <- loadDb(txdb.filename)

k <- keys(txdb, keytype = "TXNAME")
tx2gene <- select(txdb, k, "GENEID", "TXNAME")
head(tx2gene)
```

## 6. Import data table from Salmon output using txiimport 

### Use tximport to import transcript-level data.
The countsFromAbundance option of tximport uses estimated abundances to generate roughly count-scaled data, such that each column will sum to the number of reads mapped for that library. By using scaledTPM counts, the estimated proportions fit by DRIMSeq (for DTU analysis), which are generated from counts, will be equivalent to proportions of the abundance of the isoforms.
```{r tximport for transcripts-level}
library("tximport")
library("jsonlite")
library("readr") # the "readr" makes tximport quicker
txi.tx <- tximport(files, type="salmon", txOut=TRUE, countsFromAbundance="scaledTPM")

# This code returns the transcript-level expression for the 7 isoforms of Wdfy3. 
Wdfy3 <- "ENSMUSG00000043940.16"
Wdfy3_TXNAME <- subset(tx2gene, tx2gene$GENEID == Wdfy3)$TXNAME
txi.tx$counts[Wdfy3_TXNAME, ]

```

### tximport function can import the estimated counts/TPM and summarize to gene-level.
```{r tximport for gene-level}
# txi$counts will be the count table from the original salmon quantification, but gene-level summarized.
# txi$abundance will be TPM table from the original salmon quantification, but gene-level summarized
txi <- tximport(files, type="salmon", tx2gene=tx2gene)

# Alternatively, one can generate the count table from TPM (not from the original estimated counts). txi$abundance and txi.scale$abundance are the same. But txi.scale$count is generated by using the TPM value * featureLength * library size. Values of txi.scale$counts and txi$counts are very close, but txi.scale$counts accounted for transcript length changes across samples.
txi.scale <- tximport(files, type = "salmon", tx2gene = tx2gene, 
                  countsFromAbundance = "lengthScaledTPM")
```
Read here for more explaination about the difference and application of "default", "scaledTPM" and "lengthScaledTPM" by tximport. https://support.bioconductor.org/p/84883/.


### Now check your txi - the SummarizedExperiment object
```{r txi}
names(txi)
txi$counts[1:10,1:10]
txi$length[1:10,1:10]
txi$abundance[1:10,1:10]
txi$countsFromAbundance


```

```{r txi.scale}
names(txi.scale)
txi.scale$counts[1:10,1:10]
txi.scale$length[1:10,1:10]
txi.scale$abundance[1:10,1:10]
txi.scale$countsFromAbundance
```

## 7. write.csv to save the quantification data to the output folder
```{r savetxi}
# Gene-level counts
write.csv(txi$counts, paste0(wd$output, "07_RNAseq_hWDFY3Tg_20220128_SalmonCounts.csv"))

# Gene-level abundance (TPM) can be compared across genes or samples
write.csv(txi$abundance, paste0(wd$output, "07_RNAseq_hWDFY3Tg_20220128_SalmonAbundance.csv"))
```

## 8. Differential expression analysis
### 8.1 Create a _DESeqDataSet_ object
```{r DESeqDataSet}
# Construct a DESeqDataSet (dds) using txi
library("DESeq2")
dds <- DESeqDataSetFromTximport(txi, coldata, design = ~treatment) # dds is now ready for DESeq() see DESeq2 vignette
## We can quickly check the millions of fragments that could be mapped by Salmon to the genes (the second argument of round tells how many decimal points to keep).
round(colSums(assay(dds)) / 1e6, 1 )
genetable <- data.frame(gene.id = rownames(txi$counts)) 
names(assays(dds))
head(assay(dds), 3)

```
 
```{r edgeR, eval = FALSE, echo = FALSE}
# EdgeR
library("edgeR")
cts <- txi$counts
normMat <- txi$length
normMat <- normMat/exp(rowMeans(log(normMat)))
o <- log(calcNormFactors(cts/normMat)) + log(colSums(cts/normMat))
dge <- DGEList(counts = cts,
               samples = coldata,
               genes = genetable)
dge <- scaleOffset(dge, t(t(log(normMat)) + o))
names(dge)
```


### 8.2 Pre-filtering the DE data
In order to reduce the size of the object, and to increase the speed of our functions, we can remove the rows that have no or nearly no information about the amount of gene expression.
```{r dds}
# dds
nrow(dds)
## Here we perform a minimal pre-filtering to keep only rows that have at least 10 reads total. Note that more strict filtering to increase power is automatically applied via independent filtering on the mean of normalized counts within the results function.
dds <- dds[rowSums(counts(dds)) >= 10, ]
nrow(dds)
quantile(counts(dds)[,1], c(.01, .05, .50))

## For some datasets, it may make sense to perform additional filtering. For example, one can specify that at least 3 samples have a count of 10 or higher. One recommendation for the number of samples would be set to the smallest group size. Such a rule could be specified by creating a logic vector and subsetting the dds as above. Here is an example of another rule we could have used (here not used for filtering):
#### dds <- dds[rowSums(counts(dds) >= 10) >= 3,] # at least 3 samples with a count of 10 or higher


```

```{r dge, eval = FALSE, echo= FALSE}
# dge
dge <- dge[rowSums(round(dge$counts)) > 1, ]
all(rownames(dge) == rownames(dds))
dge <- dge[filterByExpr(dge),]
```

### 8.3 Variance stablizing transformation 

```{r vst, fig.height = 4, fig.width=4}
library("vsn")
# Transformation with vst (for n>30)
vsd <- vst(dds, blind = FALSE)
head(assay(vsd), 3)
meanSdPlot(assay(vsd), ranks = FALSE)

```

```{r rlog, fig.height = 4, fig.width=4}
# Transformation with rlog (for n<30)
rld <- rlog(dds, blind = FALSE)
head(assay(rld), 3)
meanSdPlot(assay(rld), ranks = FALSE)
```


### 8.4 Exploratory analysis
#### Sample distances
Assess overall similarity between samples: Which samples are similar to each other, which are different? Does this fit to the expectation from the experimentâ€™s design? To ensure we have a roughly equal contribution from all genes, we use it on the transfored data. 


```{r dist, fig.height = 4, fig.width=5}
# Plot sample-to-sample distances using the rlog-transformed values
sampleDists <- dist(t(assay(rld)))
sampleDists
sampleDistMatrix <- as.matrix(sampleDists)
rownames(sampleDistMatrix) <- paste(rld$treatment, rld$subject, sep = " - ")
colnames(sampleDistMatrix) <- NULL
colors <- colorRampPalette(rev(brewer.pal(9, "Blues")))(255)
pheatmap(sampleDistMatrix,
         clustering_distance_rows = sampleDists,
         clustering_distance_cols = sampleDists,
         col = colors)

```


```{r PoissonDistance, fig.height = 4, fig.width=5}
# Plot sample-to-sample distances using the Poisson distance. This measure of dissimilarity between counts also takes the inherent variance structure of counts into consideration when calculating the distances between samples. The PoissonDistance function takes the original count matrix (not normalized) with samples as rows instead of columns, so we need to transpose the counts in dds.
library("PoiClaClu")
poisd <- PoissonDistance(t(counts(dds)))
samplePoisDistMatrix <- as.matrix(poisd$dd)
rownames(samplePoisDistMatrix) <- paste(vsd$treatment, vsd$subject, sep = " - ")
colnames(samplePoisDistMatrix) <- NULL
pheatmap(samplePoisDistMatrix,
         clustering_distance_rows = poisd$dd,
         clustering_distance_cols = poisd$dd,
         col = colors)
```



#### PCA plot
Another way to visualize sample-to-sample distances is a principal components analysis (PCA). In this ordination method, the data points (here, the samples) are projected onto the 2D plane such that they spread out in the two directions that explain most of the differences (figure below). The x-axis is the direction that separates the data points the most. The values of the samples in this direction are written PC1. The y-axis is a direction (it must be orthogonal to the first direction) that separates the data the second most. The values of the samples in this direction are written PC2. The percent of the total variance that is contained in the direction is printed in the axis label. Note that these percentages do not add to 100%, because there are more dimensions that contain the remaining variance (although each of these remaining dimensions will explain less than the two that we see).

```{r PCA_DESeq2, fig.height = 4, fig.width = 8}
# PCA plot using DESeq2
p1_vsd <- plotPCA(vsd, intgroup = c("treatment", "subject"))
p1_rld <- plotPCA(rld, intgroup = c("treatment", "subject"))
plot_grid(p1_vsd, p1_rld, ncol = 2)

```

```{r PCA ggplot, fig.height=4, fig.width=4}
# PCA plot using qqplot
## c("treatment", "subject")
pcaData <- plotPCA(rld, intgroup = c("treatment", "subject"), returnData = TRUE)
pcaData
percentVar <- round(100 * attr(pcaData, "percentVar"))
ggplot(pcaData, aes(x = PC1, y = PC2, color = treatment, shape = subject)) +
  geom_point(size =3) +
  xlab(paste0("PC1: ", percentVar[1], "% variance")) +
  ylab(paste0("PC2: ", percentVar[2], "% variance")) +
  coord_fixed()
```


```{r PCAfinal, fig.height=4, fig.width=4}
# Now modify the code to remove "subject"
pcaData <- plotPCA(rld, intgroup = "treatment", returnData = TRUE)
pcaData
percentVar <- round(100 * attr(pcaData, "percentVar"))
ggplot(pcaData, aes(x = PC1, y = PC2, color = treatment)) +
  geom_point(size =3) +
  xlab(paste0("PC1: ", percentVar[1], "% variance")) +
  ylab(paste0("PC2: ", percentVar[2], "% variance")) +
  coord_fixed()
```



#### MDS plot
Another plot, very similar to the PCA plot, can be made using the multidimensional scaling (MDS) function in base R. This is useful when we donâ€™t have a matrix of data, but only a matrix of distances. Here we compute the MDS for the distances calculated from the VST data and plot these in a figure below.
```{r MDS, fig.height = 4, fig.width = 8}
# MDS plot from the VST data
mds <- as.data.frame(colData(vsd))  %>%
  cbind(cmdscale(sampleDistMatrix))
p1 <- ggplot(mds, aes(x = `1`, y = `2`, color = treatment, shape = subject)) +
  geom_point(size = 3) + coord_fixed()
# MDS plot with poisson distribution
mdsPois <- as.data.frame(colData(dds)) %>%
  cbind(cmdscale(samplePoisDistMatrix))
p2 <- ggplot(mdsPois, aes(x = `1`, y = `2`, color = treatment, shape = subject)) +
  geom_point(size = 3) + coord_fixed()

plot_grid(p1, p2, ncol=2)
```


#### Clustering by the top variable genes
In the sample distance heatmap made previously, the dendrogram at the side shows us a hierarchical clustering of the samples. Such a clustering can also be performed for the genes. Since the clustering is only relevant for genes that actually carry a signal, one usually would only cluster a subset of the most highly variable genes. Here, for demonstration, let us select the 20 genes with the highest variance across samples. We will work with the VST data.
```{r clustering, fig.height = 8, fig.width = 7}
library("genefilter")
topVarGenes <- head(order(rowVars(assay(rld)), decreasing = TRUE), 30)
mat  <- assay(vsd)[ topVarGenes, ]
mat  <- mat - rowMeans(mat)
anno <- as.data.frame(colData(vsd)[, c("subject","treatment")])
pheatmap(mat, annotation_col = anno)

heatmap.2(assay(rld)[topVarGenes, ], scale="row",
trace="none", dendrogram="column",
col = colorRampPalette( rev(brewer.pal(9, "RdBu")) )(255))

```

### 8.5 Differential expression (DE) analysis
```{r DESeq}
dds <- DESeq(dds) # the estimation of size factors (controlling for differences in the sequencing depth of the samples), the estimation of dispersion values for each gene, and fitting a generalized linear model.
res <- results(dds, contrast = c("treatment", "OE", "Control")) # default is padj<0.1
mcols(res, use.names = TRUE) # check the metadata of res
head(res)
table(res$padj<0.1)
summary(res)

```

```{r res.05}
# Lower the false discovery rate threshold (the threshold on padj in the results table). We should inform the results() function about it, so that the function can use this threshold for the optimal independent filtering that it performs:
res.05 <- results(dds, contrast = c("treatment", "OE", "Control"), alpha = 0.05)
table(res.05$padj < 0.05)
summary(res.05)
```

```{r shrink}
# Shrink the log2FoldChange for visualization
## NOTE: Shrinking the log2 fold changes will not change the total number of genes that are identified as significantly differentially expressed. The shrinkage of fold change is to help with downstream assessment of results. For example, if you wanted to subset your significant genes based on fold change for further evaluation, you may want to use shruken values. Additionally, for functional analysis tools such as GSEA which require fold change values as input you would want to provide shrunken values.
resultsNames(dds)
res.05_shrink <- lfcShrink(dds, coef = "treatment_OE_vs_Control", res=res.05)
#### using 'apeglm' for LFC shrinkage. If used in published research, please cite: https://doi.org/10.1093/bioinformatics/bty895

```

```{r resLFC}
# If we want to raise the log2 fold change threshold, so that we test for genes that show more substantial changes due to treatment, we simply supply a value on the log2 scale. For example, by specifying lfcThreshold = 1, we test for genes that show significant effects of treatment on gene counts more than doubling or less than halving, because 2e1=2.
resLFC1 <- results(dds, lfcThreshold = 1)
summary(resLFC1) # This is the Lyz1
```



#### Multiple testing
```{r multiple testing}
sum(res.05$pvalue < 0.05, na.rm=TRUE)
sum(!is.na(res.05$pvalue))
sum(res$padj < 0.05, na.rm=TRUE)
res.05Sig <- subset(res.05, padj < 0.05)
head(res.05Sig[ order(res.05Sig$log2FoldChange), ])
head(res.05Sig[ order(res.05Sig$log2FoldChange, decreasing = TRUE), ])
```


#### Plotting results
```{r plotcounts, fig.height=4, fig.width=4}
# Plot counts: The counts plotted here are the normalized count by DESeq()
topGene <- rownames(res.05)[which.min(res.05$padj)]
plotCounts(dds, gene = topGene, intgroup=c("treatment"))

Wdfy3 <- "ENSMUSG00000043940.16"
plotCounts(dds, gene = Wdfy3, intgroup=c("treatment"))


```


```{r plotCounts, fig.height=6, fig.width=8}
# Plot counts: The counts plotted here are the normalized count by DESeq()
library("ggbeeswarm")
geneCounts <- plotCounts(dds, gene = Wdfy3, intgroup = c("treatment","subject"),
                         returnData = TRUE)
p1 <- ggplot(geneCounts, aes(x = treatment, y = count, color = subject)) +
  scale_y_log10() +  geom_beeswarm(cex = 3) + ggtitle("Wdfy3")
geneCounts <- plotCounts(dds, gene = Lyz1, intgroup = c("treatment","subject"),
                         returnData = TRUE)
p2 <- ggplot(geneCounts, aes(x = treatment, y = count, color = subject)) +
  scale_y_log10() +  geom_beeswarm(cex = 3) + ggtitle("Lyz1")
plot_grid(p1, p2, ncol=2)

```

```{r MAplot, fig.height=4, fig.width=4}
# MA plot
### The MA plot represents each gene with a dot. The x axis is the average expression over all samples, the y axis the log2 fold change between treatment and control. Genes with an adjusted p value below a threshold (here 0.1, the default) are shown in red. This plot demonstrates that only genes with a large average normalized count contain sufficient infor- mation to yield a significant call. 
plotMA(res.05, ylim = c(-10, 10))
plotMA(res.05_shrink, ylim = c(-10, 10))
```

```{r plotDispersion, fig.height=4, fig.width=4}
# Plot dispersion
### The function plotDispEsts visualizes DESeq2's dispersion estimates: The black points are the dispersion estimates for each gene as obtained by considering the information from each gene separately. Unless one has many samples, these values uctuate strongly around their true values. Therefore, we fit the red trend line, which shows the dispersions' dependence on the mean, and then shrink each gene's estimate towards the red line to obtain the final estimates (blue points) that are then used in the hypothesis test. The blue circles above the main \cloud" of points are genes which have high gene-wise dispersion estimates which are labelled as dispersion outliers. These estimates are therefore not shrunk toward the fitted trend line.
plotDispEsts(dds, ylim = c(1e-6, 1e1) )

```

```{r resHist, fig.height=4, fig.width=4}
# Histogram of the p values returned by the test for differential expression
hist(res$pvalue, breaks=20, col="grey" )

```



#### Exporting results
```{r exportingDE, eval= FALSE}
# Ordered the results
res.05_ordered <- res.05[order(res.05$pvalue),]
head(res.05_ordered)
res.05_shrink_ordered <- res.05_shrink[order(res.05_shrink$pvalue),]
head(res.05_shrink_ordered)
# Write csv
#### With shrinked fold change
write.csv(res.05_shrink_ordered, paste0(wd$output, "07_RNAseq_hWDFY3Tg_20220128_DESeq2.csv"))

#### Without shrinked fold change
write.csv(res.05_ordered, paste0(wd$output, "07_RNAseq_hWDFY3Tg_20220128_DESeq2_noShrink.csv"))



```

## 9. AnnotationDb: Access the AnnotationHub Web Service
To use AnnotationHub to access the AnnotationHub Web Service in order to find the gene symbol using ENSEMBLE ID as the key. Reference: https://seandavi.github.io/ITR/AnnotationHub.html
```{r AnnotationHub, eval= FALSE}
# Load AnnotationHub
library(AnnotationHub)
# Create an AnnotationHub object
ah <- AnnotationHub()
# look at the show method for the hub object ah
ah
unique(ah$dataprovider)
unique(ah$species)
# Look at the AnnotationHub object in a browser using the display() function
#### d <- display(ah)
unique(ah$rdataclass)
# The metadata underlying this hub object can be retrieved
meta <- mcols(ah)
```

```{r GRanges, eval= FALSE, echo= FALSE}
# Extract rdataclass: GRanges
grs <- query(ah, "GRanges")
grs
grs <- ah[ah$rdataclass == "GRanges",]
orgs <- subset(ah, ah$rdataclass == "OrgDb") # Can also use query(ah, "OrgDb") to return the same resutls.
orgs

```

```{r queryah, eval= FALSE}
#  Using AnnotationHub to retrieve data: 
## Query the annotationhub metadata
query(ah, 'mm10', 'txdb')
# We are working with mouse and we will get the OrgDb package.
query(ah, 'org.Mm.eg.db')
orgdb = ah[["AH92582"]]
# The two lines below will do the same
## sub_ah <- query(ah, c("Mus musculus", "OrgDb"))
## orgdb <- query(sub_ah, "OrgDb")[[1]]

# Look at the orgdb object
columns(orgdb)
keytypes(orgdb)
head(keys(orgdb, keytype="ENTREZID"))
head(keys(orgdb, keytype="ENSEMBL"))
head(keys(orgdb, keytype="SYMBOL"))
```



```{r mergeIDs, eval= FALSE}
# Select from AnnotationHub Database 
select(orgdb, keys="ENSMUSG00000043940", columns=c("SYMBOL"), keytype="ENSEMBL")
TgDE <- read.csv(paste0(wd$output, "07_RNAseq_hWDFY3Tg_20220128_DESeq2.csv"))
names(TgDE)[1]<-paste("ENSEMBL")
TgDE$ENSEMBL <- sub("\\..*", "", TgDE[,1]) # or substr(rownames(res), 1, 15)

```

```{r SaveSymbol, eval= FALSE}
# Match ENSEMBL ID and SYMBOL
keys = TgDE[,1]
length(keys)
unique(keys)
TgDE_ensembl = select(orgdb, keys=keys, columns=c("SYMBOL"), keytype="ENSEMBL") # Jianting: this is where the numbers of output from Hanrui and mine are different: Hanrui ~21615, Me ~16974. Hanrui: this time it's 16981.
write.csv(TgDE_ensembl, file = paste0(wd$output, "07_RNAseq_hWDFY3Tg_20220128_ENSEMBL_SYMBOL.csv"))


```

```{r DEwithSymbols, eval= FALSE}
# Merge the two dataframes and save the DESeq2 results
DE <- merge(TgDE, TgDE_ensembl, by = "ENSEMBL")
write.csv(DE, file = paste0(wd$output, "07_RNAseq_hWDFY3Tg_20220128_DESeq2_symbol.csv"))

```



## 10. Prepare the rnk file and convert to human orthologs as well.
### Prepare the rnk file and the final DE outputs. 
```{r rnk, eval= FALSE}
# Read the DESeq2 results
DE <- read.csv(paste0(wd$output, "07_RNAseq_hWDFY3Tg_20220128_DESeq2_symbol.csv"), header = TRUE, sep = ",")

## Filter to remove all the NAs 
DEnoNA <- DE %>% filter(!is.na(SYMBOL) & !is.na(pvalue) & !is.na(padj))


## Filter to remove duplicated SYMBOLS / updated by distinc funtion on 2021.12.12 by JS
DEfinal <- DEnoNA %>% distinct(SYMBOL, .keep_all = TRUE) 
nrow(DEfinal)
###duplicate <- DEnoNA[which(duplicated(DEnoNA$SYMBOL)),]
###duplicate_SYMBOL <- duplicate$SYMBOL
###DEfinal <- DEnoNA[!grepl(paste(duplicate_SYMBOL, collapse = "|"), DEnoNA$SYMBOL),]

## Prepare the rnk file and save to the wd$output
### Add a rank column using the following calculation, make sure to use p value, not padj.  
DEfinal$rank = -log10(DEfinal$pvalue) * sign(DEfinal$log2FoldChange)
### order by rank and subset SYMBOL and rank column
rnk = DEfinal[order(DEfinal$rank, decreasing = TRUE), 8:9]
### Write to a .rnk file
write.table(rnk, file=paste0(wd$output, "07_RNAseq_hWDFY3Tg_20220128_DESeq2_symbol.rnk"), quote = FALSE, sep = "\t", row.names = FALSE, col.names = FALSE)

## Filter the top DE genes and save all the final results to wd$output
upfinal <- DEfinal[DEfinal$padj < 0.05 & DEfinal$log2FoldChange > 0.58,]
downfinal <- DEfinal[DEfinal$padj < 0.05 & DEfinal$log2FoldChange < -0.58,]
write.csv(DEfinal, file = paste0(wd$output, "07_RNAseq_hWDFY3Tg_20220128_DESeq2_symbol_final.csv"))
write.csv(upfinal, file = paste0(wd$output, "07_RNAseq_hWDFY3Tg_20220128_DESeq2_symbol_upfinal.csv"))
write.csv(downfinal, file = paste0(wd$output, "07_RNAseq_hWDFY3Tg_20220128_DESeq2_symbol_downfinal.csv"))

```

### Include the Log2FC without shrinked fold change
```{r noShrink, eval= FALSE}
## The res.05_ordered has the log2FoldChange value before the lfc shrink.
res.05_ordered <- read.csv(paste0(wd$output, "07_RNAseq_hWDFY3Tg_20220128_DESeq2_noShrink.csv"))
names(res.05_ordered)[1]<-paste("ENSEMBL")
names(res.05_ordered)[3]<-paste("log2FoldChange_noShrink")
res.05_ordered$ENSEMBL <- sub("\\..*", "", res.05_ordered[,1])
noShrink <- res.05_ordered[, c("ENSEMBL", "log2FoldChange_noShrink")]

## Merge DEfinal with noShrink
DE_noShrink_final <- merge(DEfinal, noShrink, by = "ENSEMBL")

## Filter the top DE genes and save all the final results to wd$output
write.csv(DE_noShrink_final, file = paste0(wd$output, "07_RNAseq_hWDFY3Tg_20220128_DESeq2_symbol_final_noShrink.csv"))

```



### Convert the mouse symbols in the rnk file to human orthologs for use of MSigDB and GSEA analysis. 
```{r rnkhuman, eval= FALSE}
# First use g:Orth to translate gene identifiers between organisms (from mouse to human) and input the results.
orth <- read.csv(paste0(wd$output, "gProfiler_mmusculus_hsapiens_2-19-2022.csv"), header = TRUE, sep = ",")

#ATTENTION: column "ortholog_name" is usually where the N/As are, AND the "empty" cells, most of the "novel protein" have two different rows in "initial_alias" with one filled with ortholog_name while the other is "empty". SO by just removing the N/A results in leaving all with "empty" cells in orthlog_name, using "distinct", which treats "empty" as an object, randomly keeps one empty cells. This is why you see there are 32 empty cells in orthlog_name of orthfinal and only one was left in orthfinal2.

## Filter to remove all the "N/A" in the ortholog_name
orth <- orth[which(orth$ortholog_name != "N/A",),] 
nrow(orth)
## Filter to remove duplicate for one-to-one mapping / updated by distinct funtion on 2021.12.12 by JS
orthfinal <- orth %>% distinct(initial_alias, .keep_all = TRUE)
nrow(orthfinal)
orthfinal2 <-  orthfinal %>% distinct(ortholog_name, .keep_all = TRUE)
nrow(orthfinal2)
orthfinal2 <- orthfinal2[, c("initial_alias", "ortholog_name")]
nrow(orthfinal2)
colnames(orthfinal2) <- c("SYMBOL", "hSYMBOL")
head(orthfinal2)

###duplicate_morth <- orth[which(duplicated(orth$initial_alias)),]
###duplicate_msymbol <- duplicate_morth$initial_alias
###orth_munique <- orth[!grepl(paste(duplicate_msymbol, collapse = "|"), orth$initial_alias),]
###duplicate_horth <- orth_munique[which(duplicated(orth_munique$ortholog_name)),]
###duplicate_hsymbol <- duplicate_horth$ortholog_name
###orthfinal <- orth_munique[!grepl(paste(duplicate_hsymbol, collapse = "|"), orth_munique$ortholog_name),]
###orthfinal <- orthfinal[, c("initial_alias", "ortholog_name")]
###nrow(orthfinal2)
###colnames(orthfinal) <- c("SYMBOL", "hSYMBOL")
###head(orthfinal)

sum(orthfinal=="") # Sum of empy cell 
which(orthfinal2$hSYMBOL=="", arr.ind=TRUE) # Specify which are empty

## Merge rnk and orthfinal
rnk$SYMBOL <- toupper(rnk$SYMBOL)
merge <- merge(rnk, orthfinal2, by = "SYMBOL") #inner join
hrnk <- merge %>% dplyr::select(hSYMBOL, rank) %>% arrange(desc(rank))

## REPLACE blank (not space) with a value checked manually
hrnk[hrnk == ""] <- "THAP2"
### Write to a .rnk file
write.table(hrnk, file=paste0(wd$output, "07_RNAseq_hWDFY3Tg_20220128_DESeq2_humanortholog.rnk"), quote = FALSE, sep = "\t", row.names = FALSE, col.names = FALSE)
```



## 11. Obtain the normalized count matrix by DESeq() with gene symbol
Also for background set for overrepresentation analysis.
```{r normcounts, eval= FALSE}
nrow(dds) # The dds here should be the dds output after DEseq(dds), which means normalized counts.

# Convert to data.frame
ddsdf <- data.frame(counts(dds))
nrow(ddsdf) 
head(ddsdf)
ddsdf$ENSEMBL <- rownames(ddsdf)
ddsdf <- ddsdf[, c("ENSEMBL", "CTRL_BMDM_1", "CTRL_BMDM_2","CTRL_BMDM_3","CTRL_BMDM_4","CTRL_BMDM_5", "hWDFY3_BMDM_1", "hWDFY3_BMDM_2", "hWDFY3_BMDM_3", "hWDFY3_BMDM_4", "hWDFY3_BMDM_5")]
ddsdf$ENSEMBL <- substr(ddsdf$ENSEMBL, 1, 18)

# Match ENSEMBL ID and SYMBOL
keys = ddsdf[,1]
length(keys)
length(unique(keys))
ddsdf_ensembl = select(orgdb, keys=keys, columns=c("SYMBOL"), keytype="ENSEMBL")
merge <- merge(ddsdf, ddsdf_ensembl, by = "ENSEMBL") # There are 81 ENSEMBL ID matched to more than one gene symbol. There are also duplicated symbols.
merge_noNA <- merge[!is.na(merge$SYMBOL),]

## Filter to remove duplicated SYMBOLS / updated by distinc funtion on 2021.12.12 by JS
dds_normcounts <- merge_noNA %>% distinct(SYMBOL, .keep_all = TRUE)

# Save the dds - normalized counts to csv.
write.csv(dds_normcounts, file = paste0(wd$output, "07_RNAseq_hWDFY3Tg_20220128_ddsnormcounts.csv"))
```


## 12. Obtain the rlog normalized count matrix by DESeq() with gene symbol
Also for heatmap.
```{r rlog-normcounts, eval= FALSE}

# Convert to data.frame
rlddf <- data.frame(assays(rld))
nrow(rlddf) 
head(rlddf)
rlddf$ENSEMBL <- rownames(rlddf)
rlddf <- rlddf[, c("ENSEMBL", "CTRL_BMDM_1", "CTRL_BMDM_2","CTRL_BMDM_3","CTRL_BMDM_4","CTRL_BMDM_5", "hWDFY3_BMDM_1", "hWDFY3_BMDM_2", "hWDFY3_BMDM_3", "hWDFY3_BMDM_4", "hWDFY3_BMDM_5")]
rlddf$ENSEMBL <- substr(rlddf$ENSEMBL, 1, 18)

# Match ENSEMBL ID and SYMBOL
keys = rlddf[,1]
length(keys)
length(unique(keys))
rlddf_ensembl = select(orgdb, keys=keys, columns=c("SYMBOL"), keytype="ENSEMBL")
merge <- merge(rlddf, rlddf_ensembl, by = "ENSEMBL") # There are 81 ENSEMBL ID matched to more than one gene symbol. There are also duplicated symbols.
merge_noNA <- merge[!is.na(merge$SYMBOL),]

## Filter to remove duplicated SYMBOLS / updated by distinc funtion on 2021.12.12 by JS
rld_normcounts <- merge_noNA %>% distinct(SYMBOL, .keep_all = TRUE)

# Save the dds - normalized counts to csv.
write.csv(rld_normcounts, file = paste0(wd$output, "07_RNAseq_hWDFY3Tg_20220128_rldnormcounts.csv"))
```


## 13. Visualization of DE genes using "ReportingTools".
```{r ReportingTools, eval= FALSE}
library("ReportingTools")
htmlRep <- HTMLReport(shortName="report", title="My report",
                      reportDirectory="./")
publish(upfinal, htmlRep)
url <- finish(htmlRep)
browseURL(url)
```


## 14. Session information
```{r sessionInfo}
devtools::session_info()
```


## 15. Send all the plots to the output folder
```{r}
plots.dir.path <- list.files(tempdir(), pattern="rs-graphics", full.names = TRUE) 
plots.png.paths <- list.files(plots.dir.path, pattern=".png", full.names = TRUE)
file.copy(from=plots.png.paths, to= paste0(wd$output, "figures/"))
```


